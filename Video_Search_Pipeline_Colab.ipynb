{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# üé¨ AI Video Search Pipeline - Google Colab\n",
        "\n",
        "Complete video search system with CLIP embeddings, auto-labeling, and semantic search.\n",
        "\n",
        "**Features:**\n",
        "- ‚úÖ CLIP-based video embeddings (GPU accelerated)\n",
        "- ‚úÖ Auto-labeling (actions, objects, captions)\n",
        "- ‚úÖ FAISS vector search\n",
        "- ‚úÖ FastAPI server with web UI\n",
        "- ‚úÖ Process 13K+ videos (UCF101 dataset)\n",
        "\n",
        "**Runtime:** GPU (T4 recommended)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üì¶ Step 1: Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/YOUR_USERNAME/Rag_Video_search_Pipeline.git\n",
        "%cd Rag_Video_search_Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q pyngrok  # For exposing API to internet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "token"
      },
      "source": [
        "## üîë Step 2: Set Hugging Face Token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "set_token"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Option 1: Use Colab Secrets (recommended)\n",
        "# Go to: üîë icon on left sidebar ‚Üí Add secret: HF_TOKEN\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    print(\"‚úÖ Using HF_TOKEN from Colab secrets\")\n",
        "except:\n",
        "    # Option 2: Set directly (less secure)\n",
        "    HF_TOKEN = \"\"  # Replace with your token\n",
        "    print(\"‚ö†Ô∏è  Using hardcoded token\")\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "print(f\"Token set: {HF_TOKEN[:10]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dataset"
      },
      "source": [
        "## üì• Step 3: Download Dataset\n",
        "\n",
        "Choose one:\n",
        "- **Option A:** Small subset (200 videos, ~5 min)\n",
        "- **Option B:** Full UCF101 (13K videos, ~2 hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_subset"
      },
      "outputs": [],
      "source": [
        "# Option A: Download UCF101 subset (200 videos)\n",
        "!mkdir -p ground_clips_mp4\n",
        "!wget -q https://www.crcv.ucf.edu/data/UCF101/UCF101.rar\n",
        "!unrar x -y UCF101.rar\n",
        "\n",
        "# Create subset\n",
        "!python process_subset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_full"
      },
      "outputs": [],
      "source": [
        "# Option B: Download full UCF101 (13,320 videos - 6.5GB)\n",
        "# Uncomment to use:\n",
        "\n",
        "# !mkdir -p ground_clips_mp4\n",
        "# !wget -q https://www.crcv.ucf.edu/data/UCF101/UCF101.rar\n",
        "# !unrar x -y UCF101.rar ground_clips_mp4/\n",
        "\n",
        "# # Convert AVI to MP4\n",
        "# !python convert_ucf101_videos.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_dataset"
      },
      "outputs": [],
      "source": [
        "# Check dataset\n",
        "!python check_dataset.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "models"
      },
      "source": [
        "## üöÄ Step 4: Download Models (One-time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_clip"
      },
      "outputs": [],
      "source": [
        "# Download CLIP model\n",
        "!python download_clip_model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_blip"
      },
      "outputs": [],
      "source": [
        "# Download BLIP captioning model\n",
        "!python download_blip_model.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "process"
      },
      "source": [
        "## üé¨ Step 5: Process Videos\n",
        "\n",
        "This will:\n",
        "1. Extract keyframes\n",
        "2. Generate CLIP embeddings (GPU accelerated)\n",
        "3. Auto-label videos (actions, objects, captions)\n",
        "4. Build FAISS search index\n",
        "\n",
        "**Time:**\n",
        "- 200 videos: ~10-15 minutes\n",
        "- 13K videos: ~2-3 hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_pipeline"
      },
      "outputs": [],
      "source": [
        "# Process videos with auto-labeling\n",
        "!python run_pipeline.py --enable-labeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test"
      },
      "source": [
        "## üîç Step 6: Test Search (Local)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify_search"
      },
      "outputs": [],
      "source": [
        "# Quick search test\n",
        "!python verify_search_works.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "api"
      },
      "source": [
        "## üåê Step 7: Start API Server (Public URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "start_api"
      },
      "outputs": [],
      "source": [
        "# Install ngrok for public URL\n",
        "!pip install -q pyngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Set ngrok auth token (get free token from https://ngrok.com)\n",
        "# ngrok.set_auth_token(\"YOUR_NGROK_TOKEN\")  # Uncomment and add your token\n",
        "\n",
        "# Start API server in background\n",
        "def start_api():\n",
        "    subprocess.run([\"python\", \"run_api.py\"])\n",
        "\n",
        "api_thread = threading.Thread(target=start_api, daemon=True)\n",
        "api_thread.start()\n",
        "\n",
        "# Wait for server to start\n",
        "time.sleep(10)\n",
        "\n",
        "# Create public URL\n",
        "public_url = ngrok.connect(8081)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üåê Public URL for your Video Search API:\")\n",
        "print(f\"   {public_url}\")\n",
        "print(\"\\nüì± Web Interface:\")\n",
        "print(f\"   {public_url}/static/index.html\")\n",
        "print(\"\\nüìñ API Docs:\")\n",
        "print(f\"   {public_url}/docs\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n‚ö†Ô∏è  Keep this cell running to maintain the connection!\")\n",
        "print(\"   Stop the cell to shut down the server.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_api"
      },
      "source": [
        "## üß™ Step 8: Test API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_api_call"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Test search\n",
        "url = \"http://localhost:8081/v1/search\"\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"X-API-Key\": \"changeme\"\n",
        "}\n",
        "data = {\n",
        "    \"query\": \"person playing basketball\",\n",
        "    \"top_k\": 5\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "results = response.json()\n",
        "\n",
        "print(\"üîç Search Results:\")\n",
        "print(\"=\"*70)\n",
        "for i, result in enumerate(results.get(\"results\", []), 1):\n",
        "    print(f\"\\n{i}. {result['label']}\")\n",
        "    print(f\"   Score: {result['score']*100:.1f}%\")\n",
        "    print(f\"   Time: {result['start_time']:.1f}s - {result['end_time']:.1f}s\")\n",
        "    if 'auto_labels' in result:\n",
        "        print(f\"   Caption: {result['auto_labels'].get('caption', 'N/A')}\")\n",
        "        print(f\"   Objects: {', '.join(result['auto_labels'].get('objects', [])[:5])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save"
      },
      "source": [
        "## üíæ Step 9: Save Results to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_drive"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy processed data to Drive\n",
        "!mkdir -p /content/drive/MyDrive/VideoSearch\n",
        "!cp -r data /content/drive/MyDrive/VideoSearch/\n",
        "!cp config/pipeline.yaml /content/drive/MyDrive/VideoSearch/\n",
        "\n",
        "print(\"‚úÖ Saved to Google Drive: MyDrive/VideoSearch/\")\n",
        "print(\"   - data/ (embeddings, index, metadata)\")\n",
        "print(\"   - pipeline.yaml (config)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stats"
      },
      "source": [
        "## üìä Step 10: Performance Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stats_check"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Load metadata\n",
        "metadata_path = Path(\"data/processed/metadata.json\")\n",
        "if metadata_path.exists():\n",
        "    with open(metadata_path) as f:\n",
        "        metadata = json.load(f)\n",
        "    \n",
        "    print(\"üìä Pipeline Statistics\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Total videos processed: {len(metadata)}\")\n",
        "    \n",
        "    # Count labels\n",
        "    labels = {}\n",
        "    for entry in metadata:\n",
        "        label = entry.get('label', 'unknown')\n",
        "        labels[label] = labels.get(label, 0) + 1\n",
        "    \n",
        "    print(f\"Unique action categories: {len(labels)}\")\n",
        "    print(f\"\\nTop 10 categories:\")\n",
        "    for label, count in sorted(labels.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "        print(f\"  {label:20s} - {count} videos\")\n",
        "    \n",
        "    # Check embeddings\n",
        "    embeddings_dir = Path(\"data/processed/embeddings\")\n",
        "    if embeddings_dir.exists():\n",
        "        emb_count = len(list(embeddings_dir.glob(\"*.npy\")))\n",
        "        print(f\"\\nEmbeddings generated: {emb_count}\")\n",
        "    \n",
        "    # Check FAISS index\n",
        "    index_path = Path(\"data/index/faiss.index\")\n",
        "    if index_path.exists():\n",
        "        size_mb = index_path.stat().st_size / 1024 / 1024\n",
        "        print(f\"FAISS index size: {size_mb:.1f} MB\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Pipeline complete and ready for search!\")\n",
        "else:\n",
        "    print(\"‚ùå No metadata found. Run pipeline first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reference"
      },
      "source": [
        "## üéØ Quick Commands Reference\n",
        "\n",
        "```bash\n",
        "# Check dataset\n",
        "!python check_dataset.py\n",
        "\n",
        "# Process videos\n",
        "!python run_pipeline.py --enable-labeling\n",
        "\n",
        "# Test search quality\n",
        "!python verify_search_works.py\n",
        "\n",
        "# Start API\n",
        "!python run_api.py\n",
        "\n",
        "# Check GPU usage\n",
        "!nvidia-smi\n",
        "```\n",
        "\n",
        "## üìö Resources\n",
        "\n",
        "- **GitHub:** https://github.com/YOUR_USERNAME/Rag_Video_search_Pipeline\n",
        "- **UCF101 Dataset:** https://www.crcv.ucf.edu/data/UCF101.php\n",
        "- **CLIP Model:** https://huggingface.co/openai/clip-vit-base-patch32\n",
        "- **BLIP Model:** https://huggingface.co/Salesforce/blip-image-captioning-base\n",
        "\n",
        "## üí° Tips\n",
        "\n",
        "1. **Use GPU Runtime:** Runtime ‚Üí Change runtime type ‚Üí GPU (T4)\n",
        "2. **Save to Drive:** Colab sessions timeout after 12 hours\n",
        "3. **Batch Processing:** Process in chunks if running out of memory\n",
        "4. **Public URL:** Use ngrok for sharing your API\n",
        "5. **Cost:** Colab is free! Upgrade to Pro for longer sessions\n",
        "\n",
        "---\n",
        "\n",
        "**Enjoy your AI-powered video search! üéâ**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
